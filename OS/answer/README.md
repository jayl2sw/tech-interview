# Operating System (Answer)

**운영체제**는 사용자의 하드웨어, 시스템 리소스를 제어하고 프로그램에 대한 일반적 서비스를 지원하는 시스템 소프트웨어입니다. 응용 프로그램과 하드웨어 사이의 인터페이스로 응용 프로그램들이 메모리와 CPU, 입출력 장치 등의 자원들을 사용할 수 있도록 만들어 주며 시스템 하드웨어를 관리합니다. 뿐만 아니라 응용 소프트웨어를 실행하기 위하여 하드웨어 추상화 플랫폼과 공통 시스템 서비스를 제공합니다.



#### 1. 프로세스 & 스레드

* **프로그램, 프로세스와 스레드의 차이점에 대해서 설명해주세요.**

  > 먼저, **프로그램**이란 <u>컴퓨터에서 실행될 수 있는 파일</u>을 의미합니다. **프로세스**란, 운영체제로부터 <u>시스템 자원(CPU, 메모리 주소 공간)을 할당받아 실행되고 있는 프로그램의 인스턴스</u>를 의미합니다. **스레드**란, <u>프로세스 내에서 실행되는 작업의 최소 단위</u>를 의미합니다.
  >
  > 일반적으로 운영체제는 하나의 프로세스에 대하여 하나의 주소공간을 제공하며, 프로세스 내의 사용자 스레드들은 주소 공간을 공유합니다. 스레드는 프로세스 내에서 각각의 레지스터와 Stack 영역을 할당 받고 이외의 영역(Code, Data, Heap)을 공유합니다.  
  >
  > [참고](https://gmlwjd9405.github.io/2018/09/14/process-vs-thread.html)
  
  <br>


* **멀티 프로세스와 멀티 스레드의 차이점에 대해 설명해주세요.**

  > 멀티 프로세스와 멀티 스레드는 하나의 어플리케이션을 분할하여 작업을 처리하도록 하는 공통점이 있습니다. 멀티 프로세싱의 경우 하나의 응용 프로그램을 여러개의 프로세스로 구성하는 것이고, 멀티 스레딩의 경우 하나의 프로세스로 구성하지만 여러개의 스레드로 구성하여 각 스레드가 별도의 작업을 처리하도록 하는 것을 의미합니다.
  > 멀티 프로세스의 경우 프로세스 간 Context Switching에서 [보다 많은 오버헤드](#프로세스의 컨텍스트 스위칭과 스레드의 컨텍스트 스위칭 간의 차이점은 무엇인가요?)가 발생하고 서로 메모리를 공유하지 않아 IPC 등을 이용해 통신해야하는 어려움이 있습니다. 하지만 하나의 프로세스에 문제가 발생 하더라도 해당 자식 프로세스만 죽기 때문에 다른 프로세스에 영향을 덜 미칩니다.
  >
  > 멀티 스레딩의 경우 프로세스를 생성하는데 필요한 시스템 자원 소모가 줄고 Stack 영역을 제외한 메모리를 공유하고 있기 때문에 스레드간 데이터를 주고 받기 쉽습니다. 하지만 공유 하는 자원에 대한 동기화 문제가 있기 때문에 주의 깊은 설계가 필요합니다.

  <br>

* **PCB에 대해서 설명해주세요.**

  > PCB(Process Control Block)은 운영 제에서 프로세스들의 정보를 관리하기 위해 사용되는 자료구조입니다. 각각의 프로세스가 시작될 때 PCB가 생성되며 실행되는 동안 PCB를 사용하여 해당 프로세스를 추적 및 제어하고 프로세스가 종료될 때 해당 프로세스의 PCB는 사라집니다. PCB는 고유 식별자, 현재 실행 위치, 레지스터 값, 할당된 자원 등 프로세스의 상태정보를 저장하며 이를 활용해 프로세스 관리 및 Context Switching이 이루어집니다.

  <br>

* **컨텍스트 스위칭이 무엇이고 어떤 일들이 일어나는지 설명해주세요.**

  > 하나의 CPU는 한번에 하나의 스레만을 실행시킬 수 있습니다. 이 때, 현대 CPU의 경우 빠르게 여러 개의 프로세스를 번갈아 실행하는 방식으로 동시성을 제공합니다. Context Switching이란 운영체제에서 작업하는 프로세스 또는 스레드 간의 전환 되는 것을 의미합니다. I/O 작업을 위한 인터럽트가 발생하거나 프로세스에 할당된 time slice가 만료된 경우 등의 상황에 Context Switching이 일어납니다. 
  > Context Switching은 다음과 같은 순서로 일어납니다.
  >
  > 먼저, 현재 실행중인 프로세스에 대한 상태를 PCB에 저장합니다. 이후 Ready Queue에서 다음 실행할 프로세스를 결정하고 해당 프로세스의 PCB로부터 레지스터 값과 프로그램 카운터 등의 실행 상태를 복원합니다. 이후 메모리 공간이 변경 된 경우,  프로세스 메모리 영역을 변경한 후 다음 프로세스를 진행합니다.

  <br>

* **프로세스의 컨텍스트 스위칭과 스레드의 컨텍스트 스위칭 간의 차이점은 무엇인가요?**

  > 프로세스의 Context Switching과 스레드의 Context Switching의 가장 큰 차이점은 프로세스 컨텍스트 스위칭의 경우 가상 메모리 주소 관련 처리를 추가적으로 수행한다는 점입니다. 가상 메모리 주소를 실제 메모리 주소로 변환해주는 MMU(Memory Management Unit)가 새로운 프로세스의 메모리 주소를 바라볼 수 있도록 해야하고, 실제 메모리 주소의 캐시 역할을 진행하는 TLB도 비워줘야 합니다.
  >
  > [참고](https://www.youtube.com/watch?v=Xh9Nt7y07FE)

  <br>

* **프로세스의 상태에 대해 설명해주세요.**

  > 프로세스는 다양한 상태를 가지며, 이러한 상태 전이는 운영체제에서 관리됩니다. 
  >
  > New: 처음 프로세스가 시작되면서 메모리에 적재되어 실행 준비를 마친 상태
  >
  > Ready: 프로세스가 CPU를 할당받기 위래 ready queue에서 자신의 차례를 기다리는 상태 
  >
  > Running: ready queue에 있던 프로세스가 CPU를 할당받아 실제로 수행되는 상태
  >
  > Blocked: I/O 작업 등이 필요할 때, OS에 CPU를 반환하고 device queue에 들어가 OS가 이를 수행하고 wakeup()을 기다리는 상태

<br>

#### 2. 프로세스 주소 공간

* **프로세스의 주소 공간에 대해서 설명해주세요**

  > 프로세스의 주소 공간은 운영체제가 각각의 프로세스에 할당하는 메모리 공간입니다. 각 프로세스는 독립적으로 실행되기 위해 고유한 주소 공간을 가지고 있으며 이 공간은 크게 코드, 데이터,  힙, 스택으로 나누어집니다.
  >
  > 코드 영역은 프로세스의 어셈블리어로 컴파일된 실행 코드가 위치하는 영역입니다. CPU는 이 영역의 코드를 읽어 실행합니다.
  >
  > 데이터 영역은 전역 변수, 정적 변수 등의 데이터가 저장되는 영역입니다. 데이터 영역은 초기화 된 데이터와 초기화 되지 않은데이터로 구분될 수 있습니다.
  >
  > Heap 영역은 동적으로 할당되는 메모리가 저장되는 영역입니다. 프로세스가 실행 중에 필요에 따라 메모리를 동적으로 할당하거나 해제할 수 있습니다.
  >
  > Stack 영역은 함수 호출 시 블락이 생성되며, 파라미터나 지역변수 등이 저장되는 영역입니다.
  >
  > [참고](https://velog.io/@jayl2sw/%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4Process)

* **Heap 영역과 Stack 영역에 각각 어떤 데이터가 저장되나요?**

* **Heap영역과 Stack영역 중, 접근 속도가 더 빠른 영역은 어디일까요?**

  > Heap영역의 경우 접근하고자 하는 메모리 영역의 값을 계산해야하는 반면 Stack영역의 경우 Stack 자료 구조를 사용하는만큼 LIFO이기 때문에 더 빠르게 접근할 수 있습니다.

* **다음과 같이 공간을 분할하는 이유가 있을까요?**

  > 각각의 영역을 분리함으로써 운영체제는 메모리를 효율적으로 관리할 수 있습니다. 각 영역의 목적과 특성을 이용하여 각각에 대한 메모리 관리 방식과 규칙을 설정하여 메모리 사용 및 자원 관리의 효율성이 증대됩니다. 또한, 영역별 분리는 프로세스의 보안을 강화하는 데 도움이 됩니다. 코드 영역을 읽기 전용으로 설정하여 실행 코드의 무결성을 보호하고, 데이터 영역과 힙 영역에서 쓰기 권한을 제한하여 데이터의 무단 수정을 방지합니다.

* **스레드의 주소공간은 어떻게 구성되어 있을까요?**

  > 스레드는 Code, Data, Heap 영역은 해당 스레드가 포함된 프로세스의 영역을 공유하며, 각 스레드마다 Stack 영역을 할당받습니다.



<br>

#### 3. 스케쥴러

* **단기, 중기, 장기 스케줄러에 대해 설명해주세요.**

  > 컴퓨터에는 단기, 중기, 장기 스케줄러가 있습니다. 장기 스케줄러의 경우 프로세스 실행시에 해당 프로세스를 메모리 위에 적재 하여 Ready Queue에 넣을지 말지를 결정하는 역할을 수행합니다. 중기 스케줄러의 경우 메모리에 올라와 있는 프로세스 중 Swap out 할 프로세스를 결정합니다. 마지막으로 단시 프로세서의 경우 Ready Queue에 있는 프로세스들 중 CPU를 할당할 프로세스를 결정하기 위해 사용됩니다.

* **현대 OS에서 사용되는 스케줄러 방식에 대해 설명해주세요.**

  > 현대의 시분할 시스템에서 생성된 프로세스는 모두 Ready Queue에 추가되며 장기 스케쥴러는 사용하지  않는 것이 일반적입니다.

* **OOM(Out of Memory)가 발생한 경우 Process는 어떠한 상태로 변화하나요?**

  > 메모리 부족으로 인해 필요한 자원이 사용 불가능해지면 프로세스는 `대기 상태(Waiting)`로 전환될 수 있습니다. 이 때, CPU 자원을 모두 반환하고 다른 필요한 시스템 자원을 기다립니다.
  >
  > 또한 메모리 부족으로 인해 Prorcess가 중단되어야 하는 경우 OS는 해당 Process를 일시 중단(Suspend)할 수 있습니다. 이 상태에서는 메모리 내의 해당 프로세스의 모든 페이지가 제거되며 다시 실행하기 전 복원하여야 합니다.



<br>

#### 4. 스케줄링 알고리즘

* **알고 있는 프로세스 스케줄링 알고리즘들을 말해주세요.**

  > 프로세스 스케줄링 알고리즘(단기 스케쥴링 알고리즘)은 FIFO, SJF, 우선순위큐, RR 등이 있습니다.
  > FIFO(First-In First-Out)의 경우 먼저 Ready Queue에 들어온 프로세스부터 CPU를 할당하는 방법입니다. 이와 같은 경우 CPU 점유 시간이 짧은 프로세스가 이전 프로세스 때문에 오랜 시간 기다려야 하는 경우가 발생할 수 있습니다.
  >
  > SJF(Short-Job First)의 경우 평균 대기 시간을 줄이기 위해 대기 하고 있는 프로세스 중 CPU 점유 시간이 짧은 프로세스(Short burst process)에 우선적으로 CPU를 할당하는 방식입니다. 해당 알고리즘은 계속해서 CPU 점유 시간이 짧은 프로세스가 들어오면 CPU 점유시간이 긴 프로세스의 경우 영원히 CPU를 할당 받지 못하는 Starvation 현상이 발생할 수 있습니다.
  >
  > 우선순위 큐와 같은 경우에는 프로세스마다 우선순위를 부여하고 프로세스의 우선순위에 따라 스케줄링을 수행합니다. 큐에서 가장 높은 우선순위를 가지는 프로세스가 실행되며, 동일한 우선순위를 가지는 프로세스끼리는 FCFS로 처리됩니다. 우선순위 큐는 선점형과 비선점형 두가지로 구현될 수 있습니다. 해당 알고리즘 또한 낮은 우선순위의 프로세스가 영원히 CPU를 할당 받지 못하는 Starvation 현상이 발생할 수 있습니다.
  >
  > RR(Round-Robin)은 시분할 방식으로 여러 프로세스 간에 CPU 시간을 공평하게 분할하여 실행하는 방식입니다. 각 프로세스는 동일한 Time Slice 동안 CPU를 할당받게 되고 Time Slice가 지나면 현재 실행 중인 프로세스는 중지 된 후 ready queue로 돌아가고 다음 프로세스가 실행되는 방식으로 동작합니다. 

* **RR(Round Robin) 알고리즘에서 Time Slice에 따른 trade-off를 설명해주세요.**

  > RR에서 Time Slice가 길어지면 각 프로세스들 간의 실행되는 텀이 길어져서 응답시간이 느려지고 만약 Time Slice가 짧다면 Context Switching이 더 빈번하게 일어나서 오버헤드가 발생합니다.

* **동시성과 병렬성의 차이에 대해 설명해주세요.**

* **Multi-level Feedback Queue에 대해 설명해주세요.** 

  > Multi-level Feedback Queue는 여러개의 우선순위 큐를 사용하여 프로세스를 관리하는 방식입니다. 각 Queue는 다른 우선순위를 가지며, 서로 다른 스케줄링 알고리즘을 사용할 수 있습니다. 
  > 처음 프로세스가 Queue에 도착하면 가장 높은 우선순위 큐에 할당되고 프로세스가 큐에서 실행되는 동안 프로세스의 우선순위가 feedback에 따라 변경될 수 있습니다. 예를 들어, 일정 시간동안 device queue에서 I/O 작업을 대기하는 프로세스는 우선순위가 낮은 큐로 이동될 수 있습니다. 
  >
  > 해당 알고리즘의 특징으로는 각 <u>level의 queue마다 개별적인 스케줄링 알고리즘을 적용할 수 있다</u>는 것과 각 <u>level 별로 Time Slice를 조절할 수 있다</u>는 것입니다.
  
  * **타 스케줄러와 비교 했을 때, 어떤 문제점을 해결할 수 있나요?**
  
    > MFQ 알고리즘은 다단계 큐 구조와 동적 우선순위 조정을 통해 CPU 이용률을 향상시킬 수 있습니다. MFQ 알고리즘은 프로세스의 우선순위를 동적으로 조정할 수 있습니다. 우선순위가 높은 큐에는 CPU를 많이 요구하는 중요한 작업을 배치하여 CPU가 빈번하게 활용될 수 있습니다. 
    >
    > 또한 각 큐에 할당되는 타임 슬라이스를 조절하여 자원 할당을 조정할 수 있습니다. 이를 통해 중요한 작업과 대화형 작업 사이의 균형을 유지할 수 있습니다.
    
    

<br>

#### 5. Mutex & Semaphore

* **뮤텍스와 세마포어에 대해서 설명해주세요. (공통점, 차이점)**

  > 뮤텍스와 세마포어 모두 <u>Critical Section에 대한 배타적 접근을 보장하기 위한 수단</u>으로 사용됩니다. 뮤텍스와 세마포어의 차이점으로는 <u>동작 방식</u>과 <u>공유 자원에 동시에 접근 가능한 프로세스의 수</u>가 있습니다. 먼저, mutex의 경우 키와 같이 동작하며, 뮤텍스를 소유한 프로세스만이 크리티컬 섹션에 접근할 수 있습니다. 따라서 mutex를 소유한 1개의 프로세스만 Critical Section에 접근할 수 있습니다. Semaphore의 경우 여러 개의 프로세스가 공유 변수 하나를 조작하는 방식으로 동작합니다. 따라서 해당 공유 변수의 기본값은 1 이상일 수 있으며 이 때, 프로세스들은 공유 변수를 1 줄이고 Critical Section에 접근할 수도 있습니다.

* **뮤텍스와 이진 세마포어의 차이점에 대해 설명해주세요.**

  > 뮤텍스와 이진 세마포어의 가장 큰 차이는 <u>락의 소유 여부</u>입니다. 뮤텍스의 경우 뮤텍스를 소유한 프로세스(스레드)만이 크리티컬 섹션에 접근할 수 있으며, <u>해당 프로세스만이 뮤텍스를 반환</u>할 수 있습니다. 즉, 뮤텍스를 반환할 프로세스를 특정할 수 있습니다. 하지만 이진 세마포어의 경우 공유 변수에 대한 제어권이 여러 프로세스에 존재하기 때문에 어느 프로세스에서 변경할지 알 수 없다는 것이 차이점입니다. 
  > 뮤텍스의 이러한 기능은 Process의 Context Switching이 일어난 후 스레드간의 우선 순위를 설정할 때, 뮤텍스를 소유한 스레드의 우선 순위를 뮤텍스가 필요한 스레드의 우선순위와 동일시 함으로써 Critical Section에 대한 접근을 최적화 할 수 있습니다.

* **Monitor에 대해 설명해주세요.**

  > 

* **실제 컴퓨터에서 mutex와 semaphore가 사용되는 곳을 말해주세요.**

  > File System?



<br>

#### 6. DeadLock

* **Deadlock이 발생하는 4가지 조건에 대해 설명해주세요.**
  
  > 데드락이 발생되는 4가지 조건은 상호 배제, 비선점, 점유 대기, 순환 대기입니다.
  >
  > 최소한 하나의 자원은 한번에 한개의 프로세스(스레드)에 의해서만 사용될 수 있어야 하며, 추가적인 자원을 요청할 때, 현재 점유한 자원을 해제하지 않으며, 한번 점유한 자원의 경우 타 프로세스(스레드)에 의해 선점되지 않으며, 이러한 자원과 프로세스의 대기가 순환하며 이루어져야합니다.
  
  * **deadlock을 어떤 방식으로 예방할 수 있을까요?**
  
    > 위의 네가지 조건 중 한가지 조건이 충족되지 않도록 하면됩니다. 예를 들어 프로세스들의 자원 요청에 대한 부가정보를 바탕으로 해당 자원을 제공했을 때, 데드락으로부터 안전할 때만 할당을 진행함으로써 데드락을 방지할 수 있습니다.
  
  * **현대 OS의 경우 왜 deadlock을 예방하지 않나요?**
  
    > OS와 같은 프로세스의 경우 deadlock이 아주 드물게 발생하며, 프로세스가 실행될 때마다 데드락 예측을 진행하거나 발생한 경우 detection을 진행하는 것이 큰 오버헤드를 발생시키기 때문에 데드락이 발생한 경우 사용자가 직접 프로세스를 kill 하도록 합니다.



<br>

#### 7.  가상 메모리

* **가상 메모리란 무엇인가요?**

  > 가상 메모리란 현재 실행되고 있는 프로세스의 일부만 실제로 메모리 위에 적재하고도 프로세스를 실행할 수 있게 하는 기법을 의미합니다.

* **내부 단편화와 외부 단편화에 대해 설명해주세요.**

  > 내부 단편화는 할당된 메모리 공간 내에서 사용되지 않는 부분이 발생하는 현상을 말합니다. 메모리 할당 단위가 프로세스의 크기보다 클 때 해당 메모리 블럭 공간 중 일부가 낭비되는 결과가 발생합니다.
  >
  > 외부 단편화는 여러개의 메모리 블록들 사이에 빈 공간이 발생하는 것을 의미합니다. 주로 메모리 할당 및 해제로 인해 발생하는 공간의 조각화로 인해 발생하며 이러한 조각화로 인해 큰 메모리 공간이 필요한 프로세스는 적절한 크기의 공간을 얻지 못하고 메모리 할당에 실패합니다.

* **Page Fault가 발생했을 때, 어떻게 처리하는지 설명해 주세요.**

  > Page Fault는 프로세스가 실행 중인 도중에 필요한 페이지가 현재 메모리에 없는 상태로 요청되는 것을 말합니다. Page Fault가 발생하면 CPU는 운영 체제의 PF 핸들러를 실행시키고 페이지 교체 또는 새로운 페이지 로드 등의 작업을 수행합니다. 해당 작업은 유효성 검사, 교체, 프로세스 재시작과 같은 단계로 이루어집니다.

* **Thrashing이란 무엇인가요?**

  > Thrashing이란 시스템이 너무 많은 page fault를 발생시켜서 대부분의 시간을 페이지 교체작업으로 보내는 현상을 의미합니다. 이러한 상황에서는 실제 CPU가 동작하는 시간이 부족해지고 이로 인해 성능이 매우 저하됩니다.

  * **Thrashing이 일어났을 때, 어떻게 해결할 수 있나요?**

    > 너무 많은 프로세스나 스레드를 동시에 실행하게 되면 각각에 충분한 메모리 공간이 할당되지 않아 Trashing이 발생될 수 있습니다. 이러한 경우 프로세스나 스레드의 개수를 줄여 각각에 할당되는 메모리를 늘리는 방법으로 완화할 수 있습니다.

* **Segmentation과 Paging의 차이점은 무엇인가요?**

  > 세그멘테이션과 페이징은 모두 가상 메모리 관리를 위한 방법입니다. Segmentation은 프로세스를 논리적인 기준의 세그먼트로 분할하여 관리하는 방식이며, 페이징은 일정한 크기의 페이지로 나누어 관리하는 방식입니다.
  > 페이징은 모두 일정한 크기의 페이지를 가짐으로써 외부 단편화를 해결 할 수 있으며 관리를 쉽게 합니다. 하지만 내부 단편화가 발생할 수 있습니다.

  * **둘 중, 현대 OS에서 사용하는 방식은 무엇인가요?**

    > 페이징을 사용하고 있습니다.

* **페이지 크기에 대한 Trade-Off를 설명해 주세요.**

  > 페이지 크기가 작으면 내부 단편화가 줄어들고 접근시에 필요한 데이터 양을 줄일 수 있스빈다. 하지만 페이지 테이블의 크기가 커지게 되고 Page Fault가 더 자주 발생하게 되어 오버헤드가 발생합니다. 이는 동일한 크기 만큼의 프로세스를 메모리에 올리는데 있어 한 페이지 크기가 작을수록 더 여러번 올려야 하기 때문입니다.

  * **페이지 크기와 Page Fault의 빈도, 오버헤드와의 상관관계를 설명해주세요.**

    > 페이지 크기와 Page Fault의 빈도, 오버헤드는 반비례 관계를 가집니다.

* **페이지 교체 알고리즘에 대해 설명해주세요** 
  
  * **LRU 알고리즘은 어떻게 구현할 수 있을까요?**
  * **clock 알고리즘에 대해 설명해주세요**
  
* **가상 메모리 주소를 가지고 실제 주소를 어떻게 가져올 수 있는지 설명해 주세요.**

  > 가상 주소는 페이지 번호와 페이지 내의 오프셋으로 구성되어 있습니다. 페이지 번호를 이용하여 Page Table에서 해당 페이지의 물리 메모리 주소를 찾습니다. 

* **32비트에서, 페이지의 크기가 1kb 이라면 페이지 테이블의 최대 크기는 몇 개일까요?**



##### 7-1. TLB

* **TLB란 무엇인가요?**

  > TLB란 Translation Lookaside Buffer의 약자로 가상 메모리 주소를 물리적인 메모리 주소로 변환하는 속도를 높이기 위해 사용되는 캐시입니다.

* **TLB를 쓰면 왜 빨라지나요?**

  > 가상 메모리 주소를 물리 메모리 주소로 변환하기 위해서는 Page Table에 접근하여야 합니다. 이 때, Page Table은 용량이 크기 때문에 메모리 위에 적재되어 있어 특정 페이지에 접근하기 위해서는 CPU가 메모리에 2번씩 접근해야합니다. 따라서 이러한 비효율을 줄이기 위해 더 빠른 캐시 하드웨어를 앞단에 둠으로써 빠르게 페이지 번호를 조회할 수 있습니다. 또한, TLB의 경우 별도의 하드웨어이기 때문에 병렬적으로 탐색할 수 있어 더 빠른 탐색이 가능합니다.

* **Context Switching와 TLB는 어떤 관계가 있나요?**

  > 프로세스간의 Context Switching이 이루어지고 나면 TLB에 작성된 이전 프로세스의 가상 주소와 물리 주소 매핑 정보가 더 이상 유효하지 않기 때문에 TLB의 캐시 데이터를 모두 삭제합니다. 

* **MMU는 무엇인가요?**

  > MMU란 Memory Management Unit의 약자로 CPU가 메모리에 접근하는 것을 관리하는 컴퓨터 하드웨어 부품입니다. 프로세스의 논리적 메모리 주소를 물리 메모리 주소로 변환하며 메모리 보호, 캐시 등의 역할을 수행합니다.

* **TLB와 MMU는 현대에 어디에 위치해 있나요?**

  > 이전 컴퓨터에서는 TLB와 MMU는 별도의 하드웨어로 구성되었지만 현대에 들어와서는 CPU에 내장되어 있는 것이 일반적입니다.



<br>

#### 8. 캐시 메모리



<br>

#### 9. File System